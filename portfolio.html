<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="My Site" content="">
    <meta name="Max Gittelman" content="">

    <title>Max Gittelman</title>
    <link rel="shortcut icon" href="images/index.ico" />

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Font -->
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic' rel='stylesheet' type='text/css'/>

    <!-- Custom CSS -->
    <link href="css/styles.css" rel="stylesheet" type='text/css'/>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</head>

<body>

    <div id="header"></div>
    <div id="footer"></div>
    <script>
        $("#header").load("templates/header.html #header-template");
        $("#footer").load("templates/footer.html #footer-template");
    </script>

    <!-- Page Content -->
    <div class="container portfolio-container">

        <!-- Page Heading -->
        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">Portfolio
                    <small>ML and AI</small>
                </h1>
            </div>
        </div>
        <!-- /.row -->

        <!-- Project One -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive" src="images/cnn.png" alt="">
            </div>
            <div class="col-md-5">
                <h3>Fingerprint Verification</h3>
                <h4>CNN</h4>
                <p>Convolutional Neural Network's recent success in image recognition led our team to believe we could effectively implement a network for fingerprint verification. Using two images as input, we applied convolutions with max pooling and activation functions intermittently. We then created a fully connected layer and applied a softmax function to reduce the complex features into a class. The class label was verified or rejected to train the network effectively.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Two -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive review-one" src="images/movie.png" alt="">
                <img class="img-responsive review-two" src="images/movie.jpg" alt="">
            </div>
            <div class="col-md-5">
                <h3>Predicting Movie Ratings</h3>
                <h4>Sentiment Analysis</h4>
                <p>The intent of this natural language processing problem is to predict the ratings of a movie-goer based on his/her review. In order to yield the most accurate results, I explored combinations of various pre-processing techniques on a training data set. Approaches include lemmatizing, stemming, removing stopwords, observing word frequency and comparing its accuracy to that of inverse document frequency. With the feature matrix engineered, I trained logistic regression classifiers, support vector machines of a linear kernel, and naive bayes classifiers. The model with highest predictive accuracy on the validation set was used to label the test set.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Three -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive gif" src="images/mona.gif" alt="">
                <img class="img-responsive gif" src="images/messi.gif" alt="">
                <img class="img-responsive gif" src="images/darwin.gif" alt="">
                <img class="img-responsive gif" src="images/mickey.gif" alt="">
            </div>
            <div class="col-md-5">
                <h3>Mona Lisa</h3>
                <h4>Genetic Algorithm</h4>
                <p>Genetic Algorithms are famous for their ability to evolve a population of objects into a highly fit version of themselves. This project focused on producing images that highly resembled famous drawings. By selecting, crossing, and mutating best fit images from a population of polygons, I was able to evolve the population to a desired target. </p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Four -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive" src="images/yard.png" alt="">
            </div>
            <div class="col-md-5 ship-text">
                <h3>Shipping Yard</h3>
                <h4>Nonlinear Search Planner</h4>
                <p>Here I planned out a strategy for moving containers from a ship to specific locations in a shipping yard. Due to redundancy in planning, a linear planner is inefficient in determining an optimal solution. I therefore opted to use a nonlinear partial order planner. Initially I began with empty partial plans and then by continuously adding causal links to connect states of the environment, I was able to piece together a complex partial plan. Finally, when all goal conditions have been met the partial plan can be sorted to produce a complete plan.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Five -->
        <div class="row">
            <div class="col-md-7 bellman-container">
                <img class="img-responsive bellman" src="images/bellman.png" alt="">
            </div>
            <div class="col-md-5">
                <h3>An Unpredictable World</h3>
                <h4>Markov Decision Process</h4>
                <p>I directed an agent to a goal state in an unpredictable environment. Due to the environment’s indeterminateness, an optimal policy for the agent was calculated via value iteration. The expected utility for each action at all positions is determined first. The action with the greatest expected utility is assumed to be the optimal action to take and is used to update the policy, utility gained, at that position. To optimize the map's policy for an agent, the process is repeated until convergence. Monte Carlo simulations were then run to field test and verify the model’s acceptability.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Six -->
        <div class="row">
            <div class="col-md-7 tsp">
                <img class="img-responsive" src="images/tsp.jpg" alt="">
            </div>
            <div class="col-md-5">
                <h3>The Traveling Salesman</h3>
                <h4>A* Search Algorithm</h4>
                <p>The classic traveling salesman problem is an NP-hard problem that so far requires a heuristic to find the shortest route to connect a set of points. I used the A* search algorithm because it is admissible (does not overestimate path lengths) and complete (will always find a solution if one exists). Several functions were explored to help efficiently determine the optimal path and due to its sparsity, Kruskal's algorithm was found most useful in estimating the remaining path cost. The objective function produces a mininum spanning tree at each point in time and paths of excessive length are pruned out by the heuristic.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Seven -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive anon" src="images/anon1.png" alt="">
                <img class="img-responsive anon" src="images/anon2.png" alt="">
                <img class="img-responsive anon" src="images/anon3.png" alt="">
                <img class="img-responsive anon" src="images/anon4.png" alt="">
            </div>
            <div class="col-md-5">
                <h3>Anonymous Authors</h3>
                <h4>Bayesian Inference</h4>
                <p>Given a library of articles, I trained a bayesian network to attribute an author to an anonymous piece of work. To ignore the bias of the articles content and focus on a writer’s patterns, I used stop word frequency as a measurement over term frequency. Stop word frequency was proven to be a better predictor of authorship with an order of magnitude higher accuracy over that of term frequency.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Eight -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive" src="images/logs.png" alt="">
            </div>
            <div class="col-md-5 log-text">
                <h3>Logging Database</h3>
                <h4>Runtime & Storage Tradeoffs</h4>
                <p>Utilizing combinations of data structures, I built an efficient log file database. Taking into account insertions, deletions, and look-up complexities for time and memory, I determined optimal data structures to properly manage and sort the database as needed.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Nine -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive" src="images/fsm.png" alt="">
            </div>
            <div class="col-md-5 fsm-text">
                <h3>Finite-state Machine</h3>
                <h4>Assembly Level Programming</h4>
                <p>A finite-state machine was implemented to carry out a computer's assembly instructions. I implemented procedure calls in an assembly language similar to ARM and designed an optimal finite-state machine. Instructions are fetched from memory, decoded and executed until the program reaches a halt.</p>
            </div>
        </div>
        <!-- /.row -->

        <hr>

        <!-- Project Ten -->
        <div class="row">
            <div class="col-md-7">
                <img class="img-responsive pipeline-text" src="images/pipeline.png" alt="">
            </div>
            <div class="col-md-5">
                <h3>Pipelined Datapath</h3>
                <h4>Parallel Instruction Clocking Scheme</h4>
                <p>By implementing a pipelined datapath I reduced the execution time for data processing that a single cycle and multicycle data path would require. To prevent data hazards and control flow hazards, the five stage pipeline was fitted with data forwarding methods and branch predictions. By allowing for the register files and memory writes to be present for the entire cycle, forwarding can be used to update instruction dependencies and prevent them from becoming hazards at all.</p>
            </div>
        </div>


        <hr>

    </div>
    <!-- /.container -->

</body>

</html>
